{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GOAL: To find the significant passive and kinetics parameters which contribute in differentiation of different sub-types of neurons.\n",
    "### Data: npz file generated by executing save_params function in neuroRD ajustador project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### STEP-1: Data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arky_1 = np.load('data/fitgp-arky-chan_arky120938.npz')\n",
    "data_arky_2 = np.load('data/fitgp-arky-chan_arky1382938.npz')\n",
    "data_arky_3 = np.load('data/fitgp-arky-chan_arky140938.npz')\n",
    "data_proto_1 = np.load('data/fitgp-proto-chan_proto0792938.npz')\n",
    "data_proto_2 = np.load('data/fitgp-proto-chan_proto1542938.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48,) (48,) (48,) (48,) (48,)\n"
     ]
    }
   ],
   "source": [
    "print(data_arky_1['paramnames'].shape, data_arky_2['paramnames'].shape, data_arky_3['paramnames'].shape, \n",
    "      data_proto_1['paramnames'].shape, data_proto_2['paramnames'].shape) # Verify shapes of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['params', 'paramnames', 'fitvals', 'features']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_arky_1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13,), (15,))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arky_1['fitvals'][0].shape, data_arky_1['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_df(np_data):\n",
    "    features = [text.partition('=')[0] for text in np_data['features'][:-3]]\n",
    "    features.append(np_data['features'][-3].split(':')[0])\n",
    "    df = pd.DataFrame(np_data['fitvals'], columns=features)\n",
    "    df['neuron'] = np_data['features'][-1].split('=')[-1]\n",
    "    df['model'] = np_data['features'][-2].split('=')[-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "arky_features_1 = get_feature_df(data_arky_1)\n",
    "arky_features_2 = get_feature_df(data_arky_2)\n",
    "arky_features_3 = get_feature_df(data_arky_3)\n",
    "proto_features_1 = get_feature_df(data_proto_1)\n",
    "proto_features_2 = get_feature_df(data_proto_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "arky_params_1 = pd.DataFrame(data_arky_1['params'], columns = data_arky_1['paramnames'])\n",
    "arky_params_2 = pd.DataFrame(data_arky_2['params'], columns = data_arky_2['paramnames'])\n",
    "arky_params_3 = pd.DataFrame(data_arky_3['params'], columns = data_arky_3['paramnames'])\n",
    "proto_params_1 = pd.DataFrame(data_arky_1['params'], columns = data_arky_1['paramnames'])\n",
    "proto_params_2 = pd.DataFrame(data_arky_2['params'], columns = data_arky_2['paramnames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "arky_df_1 = pd.concat([arky_params_1, arky_features_1], axis=1, sort=False)\n",
    "arky_df_2 = pd.concat([arky_params_2, arky_features_2], axis=1, sort=False)\n",
    "arky_df_3 = pd.concat([arky_params_3, arky_features_3], axis=1, sort=False)\n",
    "proto_df_1 = pd.concat([proto_params_1, proto_features_1], axis=1, sort=False)\n",
    "proto_df_2 = pd.concat([proto_params_2, proto_features_2], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 15)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_features_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 48)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto_params_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25200, 63)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = arky_df_1.append(arky_df_2)\n",
    "df = df.append(arky_df_3)\n",
    "df = df.append(proto_df_1)\n",
    "#df = df.append(proto_df_2) # features and parameters individual rows didn't match.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### STEP-2: Random forest classification model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['junction_potential', 'RA', 'RM', 'CM', 'Eleak', 'Cond_KDr_0',\n",
       "       'Cond_KDr_1', 'Cond_KDr_2', 'Cond_Kv3_0', 'Cond_Kv3_1', 'Cond_Kv3_2',\n",
       "       'Cond_KvF_0', 'Cond_KvF_1', 'Cond_KvF_2', 'Cond_KvS_0', 'Cond_KvS_1',\n",
       "       'Cond_KvS_2', 'Cond_NaF_0', 'Cond_NaF_1', 'Cond_NaF_2', 'Cond_HCN1_0',\n",
       "       'Cond_HCN1_1', 'Cond_HCN2_0', 'Cond_HCN2_1', 'Cond_KCNQ', 'Cond_NaS_0',\n",
       "       'Cond_NaS_1', 'Cond_NaS_2', 'Cond_Ca_0', 'Cond_Ca_1', 'Cond_SKCa_0',\n",
       "       'Cond_SKCa_1', 'Cond_BKCa_0', 'Cond_BKCa_1', 'Chan_HCN1_taumul',\n",
       "       'Chan_HCN2_taumul', 'Chan_HCN1_vshift', 'Chan_HCN2_vshift',\n",
       "       'Chan_NaF_vshift', 'Chan_NaF_taumul', 'Chan_NaS_vshift',\n",
       "       'Chan_NaS_taumul', 'Chan_Kv3_vshift', 'Chan_Kv3_taumul',\n",
       "       'Chan_KvS_vshift', 'Chan_KvS_taumul', 'Chan_KvF_vshift',\n",
       "       'Chan_KvF_taumul', 'response_fitness', 'baseline_pre_fitness',\n",
       "       'baseline_post_fitness', 'rectification_fitness',\n",
       "       'falling_curve_time_fitness', 'spike_time_fitness',\n",
       "       'spike_width_fitness', 'spike_height_fitness', 'spike_count_fitness',\n",
       "       'spike_ahp_fitness', 'ahp_curve_fitness',\n",
       "       'spike_range_y_histogram_fitness', 'total', 'neuron', 'model'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  ['gp'] \n",
      " Neuron_types:  ['arky' 'proto']\n"
     ]
    }
   ],
   "source": [
    "print('Model: ',pd.unique(df['model']),'\\n','Neuron_types: ', pd.unique(df['neuron']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "exclude = ['model', 'total']\n",
    "columns = [column for column in list(df.columns) if column not in exclude]\n",
    "columns_no_label = [column for column in list(df.columns) if column not in exclude or column not in ['neuron']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df[columns_no_label]\n",
    "labels = df['neuron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(['neuron', 'model', 'total'])\n",
    "df_no_labels = df.loc[:, set(df.columns) - exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cond_KDr_2</th>\n",
       "      <th>CM</th>\n",
       "      <th>Cond_HCN2_1</th>\n",
       "      <th>Cond_KvS_1</th>\n",
       "      <th>Cond_KvS_2</th>\n",
       "      <th>rectification_fitness</th>\n",
       "      <th>Cond_NaS_1</th>\n",
       "      <th>response_fitness</th>\n",
       "      <th>Cond_KvS_0</th>\n",
       "      <th>Cond_KvF_0</th>\n",
       "      <th>...</th>\n",
       "      <th>falling_curve_time_fitness</th>\n",
       "      <th>Cond_HCN1_0</th>\n",
       "      <th>Cond_Kv3_2</th>\n",
       "      <th>Cond_HCN2_0</th>\n",
       "      <th>Cond_BKCa_1</th>\n",
       "      <th>Cond_KDr_1</th>\n",
       "      <th>Cond_Ca_1</th>\n",
       "      <th>Cond_NaS_2</th>\n",
       "      <th>Chan_NaF_vshift</th>\n",
       "      <th>spike_height_fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.201521</td>\n",
       "      <td>0.010075</td>\n",
       "      <td>0.427183</td>\n",
       "      <td>4.178451</td>\n",
       "      <td>10.320133</td>\n",
       "      <td>8.210518</td>\n",
       "      <td>1.659697</td>\n",
       "      <td>1.660941</td>\n",
       "      <td>0.921858</td>\n",
       "      <td>10.747251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479820</td>\n",
       "      <td>0.304674</td>\n",
       "      <td>383.846595</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>2.066036</td>\n",
       "      <td>6.840888</td>\n",
       "      <td>0.132926</td>\n",
       "      <td>1.030384</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.001113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.009271</td>\n",
       "      <td>0.019054</td>\n",
       "      <td>0.329575</td>\n",
       "      <td>3.441697</td>\n",
       "      <td>10.376160</td>\n",
       "      <td>1.495024</td>\n",
       "      <td>1.119214</td>\n",
       "      <td>3.654072</td>\n",
       "      <td>3.338746</td>\n",
       "      <td>8.840670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519837</td>\n",
       "      <td>0.320233</td>\n",
       "      <td>271.872956</td>\n",
       "      <td>0.282693</td>\n",
       "      <td>1.740351</td>\n",
       "      <td>8.355165</td>\n",
       "      <td>1.254689</td>\n",
       "      <td>2.325295</td>\n",
       "      <td>-0.005511</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.405161</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>1.131724</td>\n",
       "      <td>2.122247</td>\n",
       "      <td>8.848264</td>\n",
       "      <td>2.329753</td>\n",
       "      <td>0.182122</td>\n",
       "      <td>2.713499</td>\n",
       "      <td>0.358007</td>\n",
       "      <td>9.407996</td>\n",
       "      <td>...</td>\n",
       "      <td>2.214393</td>\n",
       "      <td>0.017190</td>\n",
       "      <td>354.763742</td>\n",
       "      <td>0.924143</td>\n",
       "      <td>2.368642</td>\n",
       "      <td>7.812411</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>0.225693</td>\n",
       "      <td>-0.003099</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128.888614</td>\n",
       "      <td>0.025445</td>\n",
       "      <td>0.670469</td>\n",
       "      <td>1.951140</td>\n",
       "      <td>10.323037</td>\n",
       "      <td>4.408574</td>\n",
       "      <td>0.433948</td>\n",
       "      <td>5.569647</td>\n",
       "      <td>0.472506</td>\n",
       "      <td>8.566726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203141</td>\n",
       "      <td>0.086651</td>\n",
       "      <td>292.893299</td>\n",
       "      <td>0.693917</td>\n",
       "      <td>1.794903</td>\n",
       "      <td>9.850698</td>\n",
       "      <td>0.317223</td>\n",
       "      <td>1.456858</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195.231279</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>0.729558</td>\n",
       "      <td>3.465987</td>\n",
       "      <td>10.679765</td>\n",
       "      <td>7.313001</td>\n",
       "      <td>0.361717</td>\n",
       "      <td>7.235810</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>10.901112</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.408522</td>\n",
       "      <td>245.590405</td>\n",
       "      <td>2.023085</td>\n",
       "      <td>2.152569</td>\n",
       "      <td>9.850924</td>\n",
       "      <td>0.268413</td>\n",
       "      <td>0.087798</td>\n",
       "      <td>0.008843</td>\n",
       "      <td>0.348866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cond_KDr_2        CM  Cond_HCN2_1  Cond_KvS_1  Cond_KvS_2  \\\n",
       "0  175.201521  0.010075     0.427183    4.178451   10.320133   \n",
       "1   16.009271  0.019054     0.329575    3.441697   10.376160   \n",
       "2   53.405161  0.008673     1.131724    2.122247    8.848264   \n",
       "3  128.888614  0.025445     0.670469    1.951140   10.323037   \n",
       "4  195.231279  0.011546     0.729558    3.465987   10.679765   \n",
       "\n",
       "   rectification_fitness  Cond_NaS_1  response_fitness  Cond_KvS_0  \\\n",
       "0               8.210518    1.659697          1.660941    0.921858   \n",
       "1               1.495024    1.119214          3.654072    3.338746   \n",
       "2               2.329753    0.182122          2.713499    0.358007   \n",
       "3               4.408574    0.433948          5.569647    0.472506   \n",
       "4               7.313001    0.361717          7.235810    0.009319   \n",
       "\n",
       "   Cond_KvF_0  ...  falling_curve_time_fitness  Cond_HCN1_0  Cond_Kv3_2  \\\n",
       "0   10.747251  ...                    0.479820     0.304674  383.846595   \n",
       "1    8.840670  ...                    0.519837     0.320233  271.872956   \n",
       "2    9.407996  ...                    2.214393     0.017190  354.763742   \n",
       "3    8.566726  ...                    0.203141     0.086651  292.893299   \n",
       "4   10.901112  ...                    1.500000     1.408522  245.590405   \n",
       "\n",
       "   Cond_HCN2_0  Cond_BKCa_1  Cond_KDr_1  Cond_Ca_1  Cond_NaS_2  \\\n",
       "0     0.000120     2.066036    6.840888   0.132926    1.030384   \n",
       "1     0.282693     1.740351    8.355165   1.254689    2.325295   \n",
       "2     0.924143     2.368642    7.812411   0.042572    0.225693   \n",
       "3     0.693917     1.794903    9.850698   0.317223    1.456858   \n",
       "4     2.023085     2.152569    9.850924   0.268413    0.087798   \n",
       "\n",
       "   Chan_NaF_vshift  spike_height_fitness  \n",
       "0        -0.000747              0.001113  \n",
       "1        -0.005511              1.500000  \n",
       "2        -0.003099              1.500000  \n",
       "3         0.006463              1.500000  \n",
       "4         0.008843              0.348866  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc = RandomForestClassifier(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomTreesEmbedding(max_depth=5, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           random_state=None, sparse_output=True, verbose=0,\n",
       "           warm_start=False)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte.fit(df_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtc.fit(df_no_labels, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Feature importances are sorted in decending order along with feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spike_count_fitness', 0.09897477197878705),\n",
       " ('Cond_KDr_0', 0.09718447534182983),\n",
       " ('ahp_curve_fitness', 0.09708089418997809),\n",
       " ('spike_range_y_histogram_fitness', 0.07199798211013785),\n",
       " ('falling_curve_time_fitness', 0.06846900305965417),\n",
       " ('Cond_Ca_0', 0.05395345034071961),\n",
       " ('spike_ahp_fitness', 0.05116053001736296),\n",
       " ('Cond_KvS_2', 0.04301742511475009),\n",
       " ('Cond_NaF_0', 0.03871246775750917),\n",
       " ('spike_height_fitness', 0.0360724427492171),\n",
       " ('spike_time_fitness', 0.03016422630445418),\n",
       " ('RA', 0.02623532762048465),\n",
       " ('baseline_post_fitness', 0.026102273401102428),\n",
       " ('Cond_BKCa_0', 0.02604040832588241),\n",
       " ('response_fitness', 0.02537895310857948),\n",
       " ('rectification_fitness', 0.019538122388770087),\n",
       " ('Cond_KvS_1', 0.015627689918803537),\n",
       " ('Cond_NaF_2', 0.015403271486085692),\n",
       " ('Cond_KvF_0', 0.011964813419179793),\n",
       " ('Cond_NaS_1', 0.009725070759306627),\n",
       " ('Cond_KvF_2', 0.009414900620676313),\n",
       " ('Cond_Kv3_0', 0.008629687740186789),\n",
       " ('spike_width_fitness', 0.008285485134063606),\n",
       " ('Cond_Kv3_1', 0.007469371979222714),\n",
       " ('Cond_Ca_1', 0.006740800483355675),\n",
       " ('Cond_KDr_1', 0.006041673044791739),\n",
       " ('junction_potential', 0.005926999407296956),\n",
       " ('Eleak', 0.0059246577120405635),\n",
       " ('Cond_Kv3_2', 0.0051961461594715805),\n",
       " ('Cond_KCNQ', 0.004713230808986108),\n",
       " ('Cond_SKCa_1', 0.00423342794553439),\n",
       " ('Cond_BKCa_1', 0.004116544028772375),\n",
       " ('Cond_NaF_1', 0.0037330376251047486),\n",
       " ('Cond_NaS_2', 0.0035044317898754477),\n",
       " ('Chan_NaF_vshift', 0.003420260494221422),\n",
       " ('Cond_HCN2_1', 0.0030112334108472576),\n",
       " ('RM', 0.00272228126068679),\n",
       " ('Cond_HCN1_1', 0.0027103070173048935),\n",
       " ('Chan_NaF_taumul', 0.0026771221566359218),\n",
       " ('Cond_SKCa_0', 0.0026593711569751627),\n",
       " ('Cond_HCN2_0', 0.002586798838307085),\n",
       " ('Cond_NaS_0', 0.002562605042336433),\n",
       " ('Cond_KvF_1', 0.002427885290097078),\n",
       " ('Chan_Kv3_vshift', 0.0024066756241071874),\n",
       " ('Chan_NaS_vshift', 0.0023697580153559453),\n",
       " ('CM', 0.002368477305826136),\n",
       " ('Cond_HCN1_0', 0.0023535876506736984),\n",
       " ('Cond_KvS_0', 0.0018714542957635545),\n",
       " ('Chan_HCN2_vshift', 0.0017991321047466989),\n",
       " ('Chan_HCN1_vshift', 0.0017746848513710179),\n",
       " ('Chan_KvF_taumul', 0.001751078798002885),\n",
       " ('Chan_KvF_vshift', 0.001647094104645618),\n",
       " ('Chan_HCN2_taumul', 0.001613259049944749),\n",
       " ('Cond_KDr_2', 0.0015917607045514432),\n",
       " ('Chan_Kv3_taumul', 0.0014545252025064826),\n",
       " ('Chan_HCN1_taumul', 0.001434504857933561),\n",
       " ('Chan_KvS_vshift', 0.001394561096317841),\n",
       " ('Chan_NaS_taumul', 0.001364157462429043),\n",
       " ('Chan_KvS_taumul', 0.001293430336438293),\n",
       " ('baseline_pre_fitness', 0.0)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted({feature : importance for feature, importance in zip(list(df_no_labels.columns), list(rtc.feature_importances_))}.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots one tree out of 10 trees in the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = rtc.estimators_[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = df_no_labels.columns,\n",
    "                class_names = list(labels.unique()),\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('dot -Tpng tree.dot -o tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: How to evaluate the random forest classified did good.\n",
    "# TODO: How to further simplify tree to comment on the entire forest behaviour.\n",
    "# TODO: Plot high importance feature data and label them based on neuron type('proto', 'arky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to embedding rondom tree method to compare the difference between random forest.\n",
    "# Difference between random forest and tree embedding.\n",
    "# Random Forest -> Trees in forest are fixed.\n",
    "# Tree Embedding -> Trees are added to forest cluster based on need. \n",
    "# Need to search on Tree embedding techique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "rte = RandomTreesEmbedding(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
